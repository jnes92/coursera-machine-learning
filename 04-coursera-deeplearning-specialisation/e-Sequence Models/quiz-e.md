# Week 1 - Recurrent Neural Networks

1. $x^{(i)<j>}$
2. $T_x = T_y$
3. sentiment classification, gender recognition from speech
4.  $P(y^{<t>}\∣y^{<1>},y^{<2>},\dots, y^{<t−1>})$
5.  randomly sample, pass selected word to next time step
6.  exploding (overflow, because huge number)
7.  100
8.  betty, similiar to 0
9.  $\Theta_u $ , $1-\Theta_u$
10. unidirectional, depends only on x1 to x<t>

# Week 2 - Natural Language Processing & Word Embeddings 

1. false
2. non-linear dimensionality reduction
3. true
4. $boy-girl \approx brother-sister$, $boy-brother\approx girl-sister$
5. computationally wasteful
6. true
7. c,t nearby
8. 500 dims, adam optimizer
9. random init, xij number of times appears, weighting function f0 = 0
10. m1 >> m2

# Week 3 - Sequence models & Attention mechanism

1. false
2. slower, more memory, better solution
3. true
4. no, should be rnn attributed
5. true
6. t' = 1, y^t
7. true
8. large input sentence
9. cookbook
10. features of audio